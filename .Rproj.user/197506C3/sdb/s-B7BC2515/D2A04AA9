{
    "contents" : "# TODO: Add comment\n# \n# Author: shrutigupta34\n###############################################################################\n.onLoad <- function(libname, pkgname) {\n\n\t#specifying package location\n  rJava::.jaddClassPath(\"inst/java/rkafka1.0-1.0-jar-with-dependencies.jar\")\n  rJava::.jpackage(pkgname, lib.loc = libname)\n\n}\n\n#function to create Producer\n\n#Definition of the arguments\n#   /**\n#     * @param metadataBrokerList:String\n#   *            !!Mandatory list of brokers used for bootstrapping knowledge\n#   *            about the rest of the cluster format: host1:port1,host2:port2\n#   *            ... default:localhost:9092\n#   * \n#     * @param producerType:String\n#   *            !!Mandatory specifies whether the messages are sent\n#   *            asynchronously (async) or synchronously (sync) default:sync\n#   * \n#     * @param compressionCodec:String\n#   *            !!Mandatory specify the compression codec for all data\n#   *            generated: none , gzip, snappy. default:none\n#   * \n#     * @param serializerClass:String\n#   *            !!Mandatory message encoder\n#   *            default:kafka.serializer.StringEncoder\n#   * \n#     * @param partitionerClass:String\n#   *            --Optional name of the partitioner class for partitioning\n#   *            events; default partition spreads data randomly\n#               default:NULL\n#   * \n#     * @param compressedTopics:String\n#   *            --Optional allow topic level compression\n#   * #               default:NULL\n#     * @param queueBufferingMaxTime:String\n#   *            --Optional(for Async Producer only) maximum time, in\n#   *            milliseconds, for buffering data on the producer queue\n#   * #               default:NULL\n#     * @param queueBufferingMaxMessages:String\n#   *            --Optional(for Async Producer only) the maximum size of the\n#   *            blocking queue for buffering on the producer\n#   *#               default:NULL\n#     * @param queueEnqueueTimeoutTime:String\n#   *            --Optional(for Async Producer only) 0: events will be enqueued\n#   *            immediately or dropped if the queue is full -ve: enqueue will\n#   *            block indefinitely if the queue is full +ve: enqueue will\n#   *            block up to this many milliseconds if the queue is full\n#   *#               default:NULL\n#     * @param batchNumMessages:String\n#   *            --Optional(for Async Producer only) the number of messages\n#   *            batched at the producer\n#   * #               default:NULL\n#     * @return returns a Properties Object containing properties for the\n#   *         Producer, to be passed to MuProducer class\n#   */\nrkafka.startProducer = function(metadataBrokerList,producerType=\"sync\",compressionCodec=\"none\",\n\t\tserializerClass=\"kafka.serializer.StringEncoder\",partitionerClass=\"NULL\",compressedTopics=\"NULL\",\n\t\tqueueBufferingMaxTime=\"NULL\",\n\t\tqueueBufferingMaxMessages=\"NULL\",\n\t\tqueueEnqueueTimeoutTime=\"NULL\",\n\t\tbatchNumMessages=\"NULL\")\n{\n\tproducerType=as.character(producerType);\n\tcompressionCodec=as.character(compressionCodec);\n\tserializerClass=as.character(serializerClass);\n\tpartitionerClass=as.character(partitionerClass);\n\tqueueBufferingMaxTime=as.character(queueBufferingMaxTime);\n\tqueueBufferingMaxMessages=as.character(queueBufferingMaxMessages);\n\tqueueEnqueueTimeoutTime=as.character(queueEnqueueTimeoutTime);\n\tbatchNumMessages=as.character(batchNumMessages);\n\t\n\t# Create an object of the producer properties class\n\tproducerProperties <- rJava::.jnew(\"com/musigma/producer/ProducerProperties\")\n\t\n\t#set Properties from passed arguments and receive Properties Object\n\tproducerPropertiesObj <- rJava::.jcall(producerProperties,\"Ljava/util/Properties;\",\"setProducerProperties\",metadataBrokerList,producerType,compressionCodec,serializerClass,partitionerClass,compressedTopics,queueBufferingMaxTime,queueBufferingMaxMessages,queueEnqueueTimeoutTime,batchNumMessages)\n\t\n\t#Creating a producer\n\tproducer<- rJava::.jnew(\"com/musigma/producer/MuProducer\",producerPropertiesObj)\n\treturn(producer)\n}\n\n#Function for producer to send message\n#Definition of the arguments\n#   /**\n#     * @param producer:producer(Java object)\n#   *            !!Mandatory: Producer through which messages are to be sent\n#   * \n#   * @param topicName:String\n#   *            !!Mandatory: Topic to which messages are to be sent. If topicName doesn't exist, new topic is created\n#   * \n#     * @param ip:String\n#   *            !!Mandatory: ip on which producer is running\n#   * \n#     * @param message:String\n#   *            !!Mandatory: message to be sent\n#   */\nrkafka.send <-function(producer, topicName, ip, message)\n{\n\ttopicName <- as.character(topicName)\n\tip <- as.character(ip)\n\tmessage <- as.character(message)\n\t\n\trJava::.jcall(producer,\"V\",\"sendMessage\", topicName, ip, message)\n\tprint(\"INFO:Remember to close the producer after done sending messages\");\n}\n\n#function to shut down the producer\n#Definition of the arguments\n#   /**\n#     * @param producerObj:producerObj(Java object)\n#   *            !!Mandatory: Producer which is to be terminated\nrkafka.closeProducer <-function(producerObj)\n{\n  rJava::.jcall(producerObj,\"V\",\"close\")\n}\n\n#function to create high level consumer\n\n#/**\n#\t\t* Definition of arguments\n#* \n#@param zookeeperConnect\n#*            !!Mandatory:Zookeeper connection string comma separated\n#*            host:port pairs, each corresponding to a zk server. e.g.\n#*            \"127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002\"\n#*\t\t\t  default:\"127.0.0.1:2181\"\n#* @param groupId\n#*            !!Mandatory:consumer group id default:test-consumer-group\n#* @param zookeeperConnectionTimeoutMs\n#*            !!Mandatory:timeout in ms for connecting to zookeeper\n#*            default:100000\n#* @param consumerTimeoutMs\n#*            !!Mandatory:Throw a timeout exception to the consumer if no\n#*            message is available for consumption after the specified\n#*            interval default:1000\n#* @param autoCommitEnable\n#*            --Optional:default:true If true, periodically commit to\n#*            ZooKeeper the offset of messages already fetched by the\n#*            consumer. This committed offset will be used when the process\n#*            fails as the position from which the new consumer will begin.\n#* @param autoCommitIntervalMs\n#*            --Optional:default:60*1000 The frequency in ms that the\n#*            consumer offsets are committed to zookeeper.\n#* @param autoOffsetReset\n#*            --Optional:default:largest * smallest : automatically reset\n#*            the offset to the smallest offset largest : automatically\n#*            reset the offset to the largest offset anything else: throw\n#*            exception to the consumer\n#*/\n\nrkafka.startConsumer<- function(zookeeperConnect,groupId=\"test-consumer-group\",zookeeperConnectionTimeoutMs=\"100000\",consumerTimeoutMs=\"5000\",autoCommitEnable=\"true\",autoCommitInterval=\"1000\",autoOffsetReset=\"largest\"){\n\t\n\tzookeeperConnect=as.character(zookeeperConnect)\n\tgroupId=as.character(groupId)\n\tzookeeperConnectionTimeoutMs=as.character(zookeeperConnectionTimeoutMs)\n\tautoCommitEnable=as.character(autoCommitEnable)\n\tautoCommitInterval=as.character(autoCommitInterval)\n\tautoOffsetReset=as.character(autoOffsetReset)\n\tconsumerTimeoutMs=as.character(consumerTimeoutMs)\n\t\n\tHighConsumerObj<-rJava::.jnew(\"com/musigma/consumer/MuHighConsumer\",zookeeperConnect,groupId,zookeeperConnectionTimeoutMs,consumerTimeoutMs,autoCommitEnable,autoCommitInterval,autoOffsetReset)\n\n  return(HighConsumerObj)\n}\n\n#/**\n#\t\t* Reads messages from the topic passed as parameter.Waits for a time\n#* specified by consumer timeout property and then returns the messages\n#\t\t  @param HighConsumerObj:Consumer through which messages are to be read(Java Object)\t\n#\t\t  @param topicName\n#*            :The topic from which message is to be read\n#*\t\t  @return String[]: array of messages read\n#*/\nrkafka.read<-function(HighConsumerObj,topicName)\n{\n\t\n\tmessages=rJava::.jcall(HighConsumerObj,\"[Ljava/lang/String;\",\"read\", topicName)\n\tprint(\"INFO: Remember to close the consumer after reading messages. It won't work correctly next time otherwise\")\n  return(messages)\n\t\n}\n\n#function to shut down the consumer\nrkafka.closeConsumer<-function(HighConsumerObj){\n  rJava::.jcall(HighConsumerObj,\"V\",\"close\")\n}\n\n\n\n",
    "created" : 1424099265382.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "599620687",
    "id" : "D2A04AA9",
    "lastKnownWriteTime" : 1424102233,
    "path" : "/home/shrutigupta34/rkafkafinal/rkafka1.0/src/R/rkafka4.0.R",
    "project_path" : "src/R/rkafka4.0.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}